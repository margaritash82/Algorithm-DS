{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоги выполнения домашнег задания к уроку 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные взяла из задачи с урока 3\n",
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],  # стаж репетитора\n",
    "              [500, 700, 750, 600, 1450,        # средняя стоимость занятия\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]],  # квалификация репетитора\n",
    "              dtype = np.float64).T \n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1]) # поступил или нет ученик на специальность Математика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# учитывая разброс показателей x в предложенном массиве провела стандартизацию \n",
    "def standard_scaler(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res\n",
    "\n",
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scaler(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция предсказания вероятности \n",
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 .Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log (как вариант - использовать np.clip или np.where). С учетом озвученного на вебинаре задания, исключила так же 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С учетом озвученного на вебинаре задания, исключила так же 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модифицирую функцию потерь calc_logloss таким образом, чтобы массив предсказанных значений y (y_pred) не содержал 0 и 1. Для этого все 0 в массиве будут приравниваться к 0,01, все единицы - к 0,99). Применяю функцию clip к данному входному массиву функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция потерь\n",
    "def calc_logloss(y, y_pred):\n",
    "    y_pred = np.clip(y_pred, 0.01, 0.99) # добавлена модификация значений в y_pred \n",
    "    err = np.mean(- y * np.log(y_pred) - (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Подберите аргументы функции eval_LR_model для логистической регрессии таким образом, чтобы log loss был минимальным. Покажите влияние гиперпараметров на ошибку алгоритма (оптимально здесь использовать критерий остановки обучения). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(при решении данной задачи применяла функцию calc_logloss с модификация значений предсказаний (без 0 и 1) y_pred из Задания 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция подбора коэффициентов w, которую буду тестировать\n",
    "def eval_LR_model(X, y, alpha, diff):\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    i = 0 # счетчик количества пройденных итераций\n",
    "    och = 1 # переменная, определяющая разницу между err на текущем и предыдущем шаге/ итерации\n",
    "    err_list = []\n",
    "    i_list = []\n",
    "    w_list = []\n",
    "    while och >= diff:\n",
    "        z = np.dot(X, w) # log(p/(1-p))\n",
    "        y_pred = sigmoid(z) # p [0, 1]\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        err_list.append(err)\n",
    "        w -= alpha * (1/n * np.dot(X.T, (y_pred - y)))\n",
    "        w_list.append(w)\n",
    "        i = i+1\n",
    "        i_list.append(i)\n",
    "        if len(err_list)> 2:\n",
    "            och = err_list[-2]-err_list[-1]\n",
    "    print(i_list[-2], w_list[-2], err_list[-2]) \n",
    "    print(i_list[-1], w_list[-1], err_list[-1])\n",
    "           \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установила ограничение на изменение log_loss, которое задается пользователем. Посмотрела, как меняется количество операций для достижение заданного значения изменения при увеличении и уменьшении alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57508 [-8.4568781  -1.24011996 -1.48573323  7.26901084] 0.2854870638172157\n",
      "57509 [-8.4568781  -1.24011996 -1.48573323  7.26901084] 0.2854860638295222\n"
     ]
    }
   ],
   "source": [
    "w = eval_LR_model(X_st, y, alpha = 1e-2, diff = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2743669  0.1700346  0.98648447 0.21772387 0.71205276 0.34261467\n",
      " 0.99609251 0.10050152 0.30589585 0.97137141]\n",
      "[0 0 1 0 1 0 1 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28548506385975225"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sigmoid(np.dot(X_st, w))\n",
    "print(y_pred)\n",
    "print(y)\n",
    "calc_logloss(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При ораничении изменения потерь значением 0,000001 при alpha 1e-2 на итерации 57509 подобраны значения w, при которых logloss снизилась относительно значения из модели из урока 3 (0,4993). Отосительно примера из урока снижение оибки достигнуто за счет увеличени количества итераций с 2000 до 57509. При данны параметрах подобраны w не позволяющие классицировать предсказанные y_pred аналогично y (2 значения y_pred классифицируются отличными от y при границе сравнения в 0,5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68212 [-2.01943875 -0.9731686   0.84006604  2.78374195] 0.4333722258511486\n",
      "68213 [-2.01943875 -0.9731686   0.84006604  2.78374195] 0.4333712258577682\n"
     ]
    }
   ],
   "source": [
    "w = eval_LR_model(X_st, y, alpha = 1e-3, diff = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26273811 0.33508103 0.77063562 0.29764466 0.81022293 0.61328034\n",
      " 0.91493889 0.16463689 0.24630659 0.83821679]\n",
      "[0 0 1 0 1 0 1 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43337022587415996"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sigmoid(np.dot(X_st, w))\n",
    "print(y_pred)\n",
    "print(y)\n",
    "calc_logloss(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При ораничении изменения потерь значением 0,000001 при alpha 1e-3 на итерации 68213 подобраны значения w, , при которых log_loss выше, чем в Примере 1 и и лишь немного снизилась относительно задачи из урока 3 (0,4993). Т.о. параметры данного примера (alpha = 1e-1, 68213 итераций) не подходит для решения задачи по минимизации Log_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54958 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.14872080898236\n",
      "54959 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.1487198090008968\n"
     ]
    }
   ],
   "source": [
    "w = eval_LR_model(X_st, y, alpha = 1e-1, diff = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34488811 0.02666186 0.99999977 0.10721192 0.89228513 0.0963408\n",
      " 0.99999999 0.03221869 0.52432875 0.99999085]\n",
      "[0 0 1 0 1 0 1 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14871880904455187"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sigmoid(np.dot(X_st, w))\n",
    "print(y_pred)\n",
    "print(y)\n",
    "calc_logloss(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном примере подобраны параметры (alpha = 1e-1, количество итераций 54959), позволяющие минимизировать logloss до 0,1487, при этом w подбираются такие, что y_pred соответствует у при классификации полученных значений y_pred в 1 класс с вероятностью более 0,5.  \n",
    "Данный пример является оптимальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются значения признаков Х и веса, которые уже посчитаны функцией eval_LR_model, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba (X, w):\n",
    "    y_pred_proba = sigmoid(np.dot(X, w))\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34488811, 0.02666186, 0.99999977, 0.10721192, 0.89228513,\n",
       "       0.0963408 , 0.99999999, 0.03221869, 0.52432875, 0.99999085])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba (X_st, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются значения признаков Х и веса, которые уже посчитаны функцией eval_LR_model, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При решении в функцию в качестве входного параметра добавила границу вероятности, при которой объект относится к 1 или 0 классу (val_p). Если вероятность больше этой границы - объект относится к 1 классу. Параметр задается пользователем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred (X, w, val_p): \n",
    "    y_pred_proba = sigmoid(np.dot(X, w))\n",
    "    y_pred = []\n",
    "    for i in range(len(y_pred_proba)):\n",
    "        if y_pred_proba[i] > val_p:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)           \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34488811, 0.02666186, 0.99999977, 0.10721192, 0.89228513,\n",
       "       0.0963408 , 0.99999999, 0.03221869, 0.52432875, 0.99999085])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba (X_st, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred (X_st, w, val_p = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5. Посчитайте accuracy, матрицу ошибок, precision и recall, а также F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения задания буду использовать код и модель, которая применялась на уроке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss1(y, y_pred):\n",
    "    err = np.mean(- y * np.log(y_pred) - (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_LR_model_1(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    w1 = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    for i in range(1, iterations + 1):\n",
    "        z = np.dot(X, w1) # log(p/(1-p))\n",
    "        y_pred = sigmoid(z) # p [0, 1]\n",
    "        err = calc_logloss1(y, y_pred)\n",
    "        w1 -= alpha * (1/n * np.dot(X.T, (y_pred - y)))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, w, err)\n",
    "    return w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5687278067099053\n",
      "400 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5476800278385013\n",
      "600 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5369841864977791\n",
      "800 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5295551503580798\n",
      "1000 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5233765331724747\n",
      "1200 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.517849884671324\n",
      "1400 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5127677838840146\n",
      "1600 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.5080360394424424\n",
      "1800 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.503597783659264\n",
      "2000 [-27.29523293  -2.83689291  -7.16656175  22.47024986] 0.4994117173889703\n"
     ]
    }
   ],
   "source": [
    "w1 = eval_LR_model_1(X_st, y, 2000, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет Accuracy (вариант 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция расчета показателя accuracy  \n",
    "def AC (y, y_pred):\n",
    "    accuracy = sum([1 for i in range(len(y)) if y_pred[i]==y[i]])/ len(y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "y: [0 0 1 0 1 0 1 0 1 1]\n",
      "accurcy: 0.8\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = calc_pred (X_st, w1, val_p = 0.5)\n",
    "print(f'y_pred: {y_pred5}')\n",
    "print(f'y: {y}')\n",
    "print ( f'accurcy: {AC(y, y_pred5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy по модели с урока = 0,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрицу ошибок, precision, recall, accuracy и F1 реализовала в виде одной функции calc_quality (все метрики расчитываются с применением матрицы ошибок: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция построения матрицы ошибок, на вход одаются истинные значения и значения, предсказанные моделью.\n",
    "\n",
    "def calc_quality (y, y_pred):\n",
    "    TP = 0 # правильно предсказано отнесение к 1 классу (количество)\n",
    "    FP = 0 # неправильно предсказано отнесения к 1 классу (количество)\n",
    "    FN = 0 # неправильно предсказано отнесения к 0 классу\n",
    "    TN = 0 # правильно предсказано отнесение к 0 классу\n",
    "    for i in range(len(y)):\n",
    "        if y_pred[i]==y[i] and y_pred[i]==1:\n",
    "            TP += 1\n",
    "        elif y_pred[i]==y[i] and y_pred[i]==0:\n",
    "            TN += 1\n",
    "        elif y_pred[i]!=y[i] and y_pred[i]==1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    \n",
    "    print ( f'Матрица ошибок:{[[TP, FP], [FN, TN]]}')\n",
    "    \n",
    "    precision = TP/ (TP + FP)\n",
    "    print ( f'precision: {precision}')\n",
    "    \n",
    "    recall = TP/ (TP + FN)\n",
    "    print ( f'recall: {recall}')\n",
    "    \n",
    "    accuracy = (TP + TN)/len(y_pred)\n",
    "    print ( f'accuracy: {accuracy}')\n",
    "    \n",
    "    F1 = 2 * precision * recall / (precision + recall) \n",
    "    print ( f'F1: {F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчитала матрицу ошибок, precision, accuracy, recall и F1 по данным и модели с урока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "y: [0 0 1 0 1 0 1 0 1 1]\n",
      "Матрица ошибок:[[4, 1], [1, 4]]\n",
      "precision: 0.8\n",
      "recall: 0.8\n",
      "accuracy: 0.8\n",
      "F1: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = calc_pred (X_st, w5, val_p = 0.5)\n",
    "print(f'y_pred: {y_pred5}')\n",
    "print(f'y: {y}')\n",
    "calc_quality(y, y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики модели с урока:\n",
    "Матрица ошибок:[[4, 1], [1, 4]] ;\n",
    "precision: 0.8 ; \n",
    "recall: 0.8 ;\n",
    "accuracy: 0.8 ;\n",
    "F1: 0.8000000000000002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно посчитала показаели модели, получившейся оптимальной в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [0, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n",
      "y: [0 0 1 0 1 0 1 0 1 1]\n",
      "Матрица ошибок:[[5, 0], [0, 5]]\n",
      "precision: 1.0\n",
      "recall: 1.0\n",
      "accuracy: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = calc_pred (X_st, w, val_p = 0.5)\n",
    "print(f'y_pred: {y_pred}')\n",
    "print(f'y: {y}')\n",
    "calc_quality(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
